"""
Agentic RAG Graph
AjanÄ±n beyni burada tanÄ±mlanÄ±r.
DÃ¶ngÃ¼sel akÄ±ÅŸ: Agent -> (Tool Call?) -> Tools -> Agent
"""
import logging
from typing import TypedDict, Annotated, List
from langgraph.graph import StateGraph, END, START
from langgraph.graph.message import add_messages
from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage
from langgraph.prebuilt import ToolNode, tools_condition

from src.infrastructure.config import get_settings
from src.services.rag.tools import ALL_TOOLS
from src.services.rag.generator import Generator

logger = logging.getLogger(__name__)


# --- 1. STATE (HAFIZA) ---
class AgentState(TypedDict):
    """AjanÄ±n hafÄ±zasÄ±. Mesaj geÃ§miÅŸini tutar."""
    messages: Annotated[List[BaseMessage], add_messages]


# --- 2. SYSTEM PROMPT ---
SYSTEM_PROMPT = """Sen CineMind AI, bir sinema uzmanÄ± asistansÄ±n.

Elindeki araÃ§lar:
1. search_vector_db: Senaryo, yorum ve film analizleri iÃ§in kullan.
2. search_tmdb_metadata: YÃ¶netmen, oyuncu, yÄ±l gibi film kÃ¼nye bilgileri iÃ§in kullan.

KURALLAR:
- KullanÄ±cÄ± bir film hakkÄ±nda soru sorduÄŸunda, Ã¶nce uygun aracÄ± kullan.
- AraÃ§ sonucuna gÃ¶re TÃ¼rkÃ§e cevap ver.
- Bilgi bulamazsan "Bu konuda bilgim yok" de, uydurma.
- Spoiler varsa uyar.
"""


# --- 3. GRAPH BUILDER ---
def create_graph():
    """LangGraph akÄ±ÅŸÄ±nÄ± oluÅŸturur ve derler."""
    
    settings = get_settings()
    
    # Generator'Ä± baÅŸlat
    gen_service = Generator(api_key=settings.GOOGLE_API_KEY)
    
    # LLM'e Tool'larÄ± Ã¶ÄŸret (BINDING)
    llm_with_tools = gen_service._llm.bind_tools(ALL_TOOLS)

    # --- NODE: AGENT (KARAR VERÄ°CÄ°) ---
    def agent_node(state: AgentState):
        logger.info("ğŸ¤– Ajan dÃ¼ÅŸÃ¼nÃ¼yor...")
        
        # Ä°lk mesajsa system prompt ekle
        messages = state["messages"]
        if not any(isinstance(m, SystemMessage) for m in messages):
            messages = [SystemMessage(content=SYSTEM_PROMPT)] + list(messages)
        
        response = llm_with_tools.invoke(messages)
        return {"messages": [response]}

    # --- NODE: TOOLS (EYLEM) ---
    tool_node_instance = ToolNode(ALL_TOOLS)

    # --- GRAFÄ°ÄÄ° Ã‡Ä°Z ---
    workflow = StateGraph(AgentState)

    # DÃ¼ÄŸÃ¼mleri ekle
    workflow.add_node("agent", agent_node)
    workflow.add_node("tools", tool_node_instance)

    # KenarlarÄ± ekle
    workflow.add_edge(START, "agent")
    
    workflow.add_conditional_edges(
        "agent",
        tools_condition,
        {
            "tools": "tools",
            "__end__": END
        }
    )
    
    workflow.add_edge("tools", "agent")

    # GrafiÄŸi derle ve dÃ¶ndÃ¼r
    return workflow.compile()


# --- 4. KULLANIM FONKSÄ°YONU ---
def query_agent(question: str) -> str:
    """
    Agent'a soru sor ve cevap al.
    
    Args:
        question: KullanÄ±cÄ± sorusu
        
    Returns:
        Agent'Ä±n cevabÄ±
    """
    graph = create_graph()
    
    # BaÅŸlangÄ±Ã§ state'i
    initial_state = {
        "messages": [HumanMessage(content=question)]
    }
    
    # Graph'Ä± Ã§alÄ±ÅŸtÄ±r
    logger.info(f"ğŸ¯ Agent query: {question[:50]}...")
    result = graph.invoke(initial_state)
    
    # Son mesajÄ± al (AI cevabÄ±)
    final_message = result["messages"][-1]
    
    return final_message.content