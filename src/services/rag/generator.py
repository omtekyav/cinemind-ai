"""
Generator (Refactored for Agentic RAG)
LangChain Chat Model wrapper kullanƒ±yor.
"""
import logging
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

logger = logging.getLogger(__name__)


class Generator:
    """
    LangChain tabanlƒ± Generator.
    Tool binding'e hazƒ±r yapƒ±.
    """
    
    SYSTEM_PROMPT = """Sen CineMind AI, bir sinema uzmanƒ± asistansƒ±n.

KURALLAR:
1. Sadece verilen kaynaklardaki bilgileri kullan
2. Bilmiyorsan "Bu konuda bilgim yok" de
3. Spoiler i√ßeren cevaplarda uyar
4. T√ºrk√ße yanƒ±t ver
5. Kaynaklardan alƒ±ntƒ± yaparken belirt (√∂rn: "Senaryoya g√∂re...")
"""
    
    def __init__(self, api_key: str, model: str = "gemini-2.5-flash"):
        self._llm = ChatGoogleGenerativeAI(
            model=model,
            google_api_key=api_key,
            temperature=0
        )
        self._model_name = model
        logger.info(f"ü§ñ LangChain Generator ba≈ülatƒ±ldƒ±: {model}")
    
    def generate(self, query: str, context: str) -> str:
        """
        LCEL ile cevap √ºret.
        Akƒ±≈ü: Prompt -> LLM -> String Parser
        """
        prompt = ChatPromptTemplate.from_messages([
            ("system", self.SYSTEM_PROMPT),
            ("user", """KAYNAKLAR:
{context}

KULLANICI SORUSU:
{query}

CEVAP:""")
        ])
        
        chain = prompt | self._llm | StrOutputParser()
        
        try:
            answer = chain.invoke({"context": context, "query": query})
            logger.info(f"‚úÖ Cevap √ºretildi ({len(answer)} karakter)")
            return answer
        except Exception as e:
            logger.error(f"‚ùå LangChain hatasƒ±: {e}")
            return f"√úzg√ºn√ºm, ≈üu anda cevap √ºretemiyorum. Hata: {type(e).__name__}"