# src/services/imdb_scraper_service.py

import httpx
from bs4 import BeautifulSoup
from fake_useragent import UserAgent
from typing import List, Dict, Optional, Union
import logging
import asyncio
import random

logger = logging.getLogger(__name__)

class ImdbScraperService:
    def __init__(self):
        """
        IMDb scraper servisi.
        Bot korumasÄ±nÄ± aÅŸmak iÃ§in UserAgent rotasyonu kullanÄ±r.
        """
        self.ua = UserAgent(fallback='chrome')
        self.base_url = "https://www.imdb.com"
    
    def _get_headers(self) -> dict:
        """
        Her istekte farklÄ± tarayÄ±cÄ± kimliÄŸi (User-Agent) Ã¼retir.
        IMDb'nin bot tespitini atlatmak iÃ§in gerekli.
        """
        return {
            "User-Agent": self.ua.random,
            "Accept-Language": "en-US,en;q=0.9",
            "Referer": "https://www.google.com/"
        }
    
    async def fetch_reviews(
        self, 
        imdb_id: str, 
        max_reviews: int = 5
    ) -> List[Dict[str, Optional[Union[str, float]]]]:
        """
        Belirtilen IMDb ID iÃ§in kullanÄ±cÄ± yorumlarÄ±nÄ± Ã§eker.
        
        Args:
            imdb_id: Filmin IMDb ID'si (Ã¶rn: "tt0468569")
            max_reviews: Ã‡ekilecek maksimum yorum sayÄ±sÄ±
            
        Returns:
            List[Dict]: Her yorum {"source": "imdb", "title": str, 
                        "rating": float|None, "content": str} formatÄ±nda
        """
        url = f"{self.base_url}/title/{imdb_id}/reviews"
        
        # Rate limiting: IP ban Ã¶nleme
        wait_time = random.uniform(2, 4)
        logger.info(f"â³ Rate limit beklemesi: {wait_time:.2f}s - {imdb_id}")
        await asyncio.sleep(wait_time)
        
        async with httpx.AsyncClient() as client:
            try:
                response = await client.get(
                    url, 
                    headers=self._get_headers(), 
                    follow_redirects=True,
                    timeout=10.0
                )
                response.raise_for_status()
                
                return self._parse_html(response.text, max_reviews)
                
            except httpx.HTTPStatusError as e:
                logger.error(f"âŒ HTTP {e.response.status_code}: {imdb_id}")
                return []
            except httpx.RequestError as e:
                logger.error(f"âŒ Network hatasÄ±: {str(e)}")
                return []
            except Exception as e:
                logger.error(f"âŒ Beklenmeyen hata: {str(e)}")
                return []
    
    def _parse_html(self, html_content: str, limit: int) -> List[Dict]:
        """
        HTML iÃ§eriÄŸinden yorum verilerini parse eder.
        IMDb'nin 2024 HTML yapÄ±sÄ±na gÃ¶re gÃ¼ncellenmiÅŸtir.
        """
        soup = BeautifulSoup(html_content, "lxml")
        reviews = []
        
        # IMDb 2024 yapÄ±sÄ±: <article class="user-review-item">
        containers = soup.select("article.user-review-item")
        logger.info(f"ğŸ” {len(containers)} yorum container bulundu")
        
        for container in containers[:limit]:
            try:
                # 1. TITLE - Yorum baÅŸlÄ±ÄŸÄ±
                title_tag = container.select_one("h3.ipc-title__text")
                title = title_tag.get_text(strip=True) if title_tag else "No Title"
                
                # 2. CONTENT - Yorum metni
                content_tag = container.select_one(".ipc-html-content-inner-div")
                content = content_tag.get_text(separator=" ", strip=True) if content_tag else ""
                
                # 3. RATING - KullanÄ±cÄ± puanÄ± (opsiyonel)
                rating = None
                rating_tag = container.select_one(".ipc-rating-star--rating")
                if rating_tag:
                    try:
                        raw = rating_tag.get_text(strip=True)  # "10" veya "9"
                        rating = float(raw)
                    except (ValueError, IndexError):
                        pass
                
                # BoÅŸ iÃ§erik kontrolÃ¼
                if not content or len(content) < 20:
                    logger.debug(f"âš ï¸ BoÅŸ iÃ§erik atlandÄ±: {title}")
                    continue
                
                reviews.append({
                    "source": "imdb",
                    "title": title,
                    "rating": rating,
                    "content": content
                })
                
                logger.debug(f"âœ… Parse: {title[:40]}... (Rating: {rating})")
                
            except Exception as e:
                logger.warning(f"âš ï¸ Parse hatasÄ± (atlandÄ±): {e}")
                continue
        
        logger.info(f"âœ… Toplam {len(reviews)} yorum baÅŸarÄ±yla parse edildi")
        return reviews